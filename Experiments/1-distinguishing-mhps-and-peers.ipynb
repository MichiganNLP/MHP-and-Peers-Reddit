{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Distinguishing MHPs and Peers\n",
    "\n",
    "This is a simple binary classifier using unigrams. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" imports \"\"\"\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn import svm, linear_model, naive_bayes\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\"\"\" parameters \"\"\"\n",
    "KFOLDS = 10 # set desired num folds\n",
    "test_proportion = 1 / KFOLDS\n",
    "\n",
    "SHUFFLE_FIRST = True # true if shuffling before test splits\n",
    "random_seed = 20\n",
    "\n",
    "min_count = 5 # min occurences of word\n",
    "\n",
    "LabelIDX = {'mhp': 0, 'peer': 1}\n",
    "idx2Label = {v:k for k,v in LabelIDX.items()}\n",
    "\n",
    "\n",
    "classifier = 'naive_bayes' # LinearSVC, LogisticRegression\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\" load dataset \"\"\"\n",
    "\n",
    "datapath = \"path to the dataset\" # the data was in the same order as ../Data/task_data.csv\n",
    "\n",
    "df = pd.read_pickle(datapath)\n",
    "\n",
    "mhp_df = df[df['author-type'] == 'mhp']\n",
    "peer_df = df[df['author-type'] == 'non-mhp']\n",
    "\n",
    "mhp_text = list(mhp_df['top-reply-text'].values)\n",
    "peer_text = list(peer_df['top-reply-text'].values)\n",
    "mhp_index = list(mhp_df['top-reply-text'].index)\n",
    "peer_index = list(peer_df['top-reply-text'].index) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\"\"\" downsample \"\"\"\n",
    "random.seed(random_seed)\n",
    "\n",
    "peer_sample = random.sample(list(zip(peer_text, peer_index)), k=len(mhp_df))\n",
    "peer_text_sample, peer_index_sample = zip(*peer_sample)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\"\"\" determine train and test indices for the k-folds \"\"\"\n",
    "\n",
    "n_samples = len(mhp_df) # n_samples / class, based on size of smaller class for even split\n",
    "master_indices = list(range(n_samples))\n",
    "\n",
    "if SHUFFLE_FIRST:\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(master_indices)\n",
    "\n",
    "\n",
    "fold_indices = {}\n",
    "for fold in range(KFOLDS):\n",
    "\n",
    "    test_idx_start = int((fold * test_proportion) * n_samples)\n",
    "    test_idx_end = int(test_idx_start + test_proportion * n_samples)\n",
    "\n",
    "    # get indices for fold\n",
    "    test_range = list(range(test_idx_start, test_idx_end))\n",
    "    train_range = list(range(0,test_idx_start)) + list(range(test_idx_end, n_samples))\n",
    "\n",
    "    # shuffle indices\n",
    "    test_range = [master_indices[i] for i in test_range]\n",
    "    train_range = [master_indices[i] for i in train_range]\n",
    "\n",
    "    # save indices\n",
    "    fold_indices[fold] = {'train':train_range, 'test':test_range}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\"\"\" load functions \"\"\"\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return [i.lower() for i in word_tokenize(sentence)]\n",
    "\n",
    "def get_vocab(text_list, min_count=5):\n",
    "    \"\"\"\n",
    "    text_list: list of text instances\n",
    "    \"\"\"\n",
    "    vocab_count = defaultdict(lambda: 0)\n",
    "    for text in tqdm(text_list):\n",
    "        tokens = preprocess(text)\n",
    "        for t in tokens:\n",
    "            vocab_count[t] += 1\n",
    "\n",
    "    vocab_set = set()\n",
    "    for k,v in vocab_count.items():\n",
    "        if v >= min_count:\n",
    "            vocab_set.add(k)\n",
    "    return list(vocab_set)\n",
    "\n",
    "def map_instance_features(text, vocab2index):\n",
    "    tokens = preprocess(text)\n",
    "    feature_map = {} # maps features (tokens) to indices in the feature vector\n",
    "    for t in tokens:\n",
    "        if t in feature_map:\n",
    "            feature_map[vocab2index[t]] += 1\n",
    "        elif t in vocab2index:\n",
    "            feature_map[vocab2index[t]] = 1\n",
    "    return feature_map\n",
    "\n",
    "def vectorize(text_datapoints, vocab):\n",
    "    vocab2index = {vocab[i]: i for i in range(len(vocab))} #vc\n",
    "\n",
    "    feature_matrix_indices = [] # j_indices\n",
    "    indptr = [0] \n",
    "    values = []\n",
    "    \n",
    "    for text_instance in tqdm(text_datapoints):\n",
    "        feature_map = map_instance_features(text_instance, vocab2index)\n",
    "        \n",
    "        # feature map indices for this instance\n",
    "        fm_idx = list(feature_map.keys())\n",
    "\n",
    "        # feature map values\n",
    "        fm_values = list(feature_map.values())\n",
    "\n",
    "        feature_matrix_indices.extend(fm_idx)\n",
    "        values.extend(fm_values)\n",
    "        indptr.append(len(feature_matrix_indices))\n",
    "\n",
    "    feature_matrix_indices = np.asarray(feature_matrix_indices)\n",
    "    indptr = np.asarray(indptr)\n",
    "    values = np.asarray(values)\n",
    "\n",
    "    return sp.csr_matrix((values, feature_matrix_indices, indptr), shape=(len(indptr) - 1, len(vocab)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\"\"\" run k-fold experiments \"\"\"\n",
    "start = time.time()\n",
    "\n",
    "fold_vector_df = defaultdict(lambda:[])\n",
    "results_df = defaultdict(lambda:[])\n",
    "\n",
    "\n",
    "for fold in fold_indices:\n",
    "    print(\"\\nFold {}\".format(fold + 1))\n",
    "    print('-'*80)\n",
    "\n",
    "    \"\"\"\n",
    "    1. Train / Test Split\n",
    "    \"\"\"\n",
    "\n",
    "    train_range = fold_indices[fold]['train']\n",
    "    test_range = fold_indices[fold]['test']\n",
    "\n",
    "    train = [[mhp_text[i], 'mhp'] for i in train_range] + [[peer_text_sample[i], 'peer'] for i in train_range]\n",
    "    train_index = [mhp_index[i] for i in train_range] + [peer_index_sample[i] for i in train_range]\n",
    "\n",
    "    test = [[mhp_text[i], 'mhp'] for i in test_range] + [[peer_text_sample[i], 'peer'] for i in test_range]\n",
    "    test_index = [mhp_index[i] for i in test_range] + [peer_index_sample[i] for i in test_range]\n",
    "\n",
    "    points, labels = zip(*train)\n",
    "    train_label_counts = Counter(labels)\n",
    "\n",
    "    z = [i for i in range(len(points))]\n",
    "    random.shuffle(z)\n",
    "    p2 = [points[i] for i in z]\n",
    "    l2 = [labels[i] for i in z]\n",
    "    train_index = [train_index[i] for i in z]\n",
    "    points = p2\n",
    "    labels = l2\n",
    "\n",
    "    \"\"\"\n",
    "    2. Get Vocab\n",
    "    \"\"\"\n",
    "    vocab = get_vocab(points, min_count=min_count)\n",
    "    vocabsize = len(vocab)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    3. Vectorize Data\n",
    "    \"\"\"\n",
    "    train_vecs = vectorize(points, vocab)\n",
    "\n",
    "    tp, tl = zip(*test)\n",
    "    test_vecs = vectorize(tp, vocab)\n",
    "\n",
    "    \"\"\"\n",
    "    4. Get Labels\n",
    "    \"\"\"\n",
    "    train_labels = [LabelIDX[i] for i in labels]\n",
    "    train_label_counts = Counter(train_labels)\n",
    "\n",
    "\n",
    "    test_labels = [LabelIDX[i] for i in tl]\n",
    "    test_label_counts = Counter(test_labels)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    5. Save a random basline\n",
    "    \"\"\"\n",
    "    # a vector of labels that matches the distribution of the test labels\n",
    "    test_label_distribution = [] \n",
    "    for label, count in test_label_counts.items():\n",
    "        for i in range(count):\n",
    "            test_label_distribution.append(label)\n",
    "\n",
    "    random_baseline = [random.choice(test_label_distribution) for i in test_labels]\n",
    "\n",
    "    random_baseline_correct = np.sum(np.array(random_baseline) == test_labels)\n",
    "    random_baseline_accuracy = random_baseline_correct / len(test_labels)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    6. Fit Classifier\n",
    "    \"\"\"\n",
    "    if classifier == 'LinearSVC':\n",
    "        print('Fitting LinearSVC classifier...')\n",
    "        clf = svm.LinearSVC(verbose=1, max_iter=10000)\n",
    "    elif classifier == 'LogisticRegression':\n",
    "        print('Fitting LogisticRegression classifier...')\n",
    "        clf = linear_model.LogisticRegression()\n",
    "    else:\n",
    "        print('Fitting naive_bayes classifier...')\n",
    "        # defaults to naive_bayes\n",
    "        clf = naive_bayes.MultinomialNB()\n",
    "\n",
    "    clf.fit(train_vecs, train_labels)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    7. Predict\n",
    "    \"\"\"\n",
    "    predictions = clf.predict(test_vecs)\n",
    "    total_correct_predictions = np.sum(predictions == test_labels)\n",
    "    accuracy = total_correct_predictions / len(test_labels)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    8. Output accuracy\n",
    "    \"\"\"\n",
    "    print(\"\\nFOLD {} RESULTS\".format(fold + 1))\n",
    "    print(\"+\", \"-\" * 50, \"+\")\n",
    "    print('Random baseline accuracy: {:.2%}'.format(random_baseline_accuracy))\n",
    "    print('Model accuracy: {:.2%}'.format(accuracy))\n",
    "    print(\"+\", \"-\" * 50, \"+\", '\\n')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    9. Save info for analysis\n",
    "    \"\"\"\n",
    "    fold_vector_df['seed'].extend([random_seed for i in test_labels])\n",
    "    fold_vector_df['fold'].extend([fold for i in test_labels])\n",
    "    fold_vector_df['predictions'].extend([idx2Label[pred] for pred in predictions])\n",
    "    fold_vector_df['random-baseline'].extend([idx2Label[pred] for pred in random_baseline])\n",
    "    fold_vector_df['actuals'].extend([idx2Label[pred] for pred in test_labels])\n",
    "    fold_vector_df['index'].extend(test_index)\n",
    "\n",
    "\n",
    "    results_df['seed'].append(random_seed)\n",
    "    results_df['fold'].append(fold)\n",
    "    results_df['accuracy'].append(accuracy)\n",
    "    results_df['random_baseline_accuracy'].append(random_baseline_accuracy)\n",
    "    results_df['vocabsize'].append(len(vocab))\n",
    "    results_df['len(train)'].append(len(train))\n",
    "    results_df['len(test)'].append(len(test))\n",
    "    results_df['% train'].append(len(train) / (len(train) + len(test)))\n",
    "    results_df['% test'].append(len(test) / (len(train) + len(test)))\n",
    "    results_df['test label distribution'].append(test_label_counts)\n",
    "\n",
    "results_df = pd.DataFrame(results_df, columns=results_df.keys())\n",
    "fold_vector_df = pd.DataFrame(fold_vector_df, columns=fold_vector_df.keys())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "print(f\"Complete. Execution time: {total_time}s\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 165/17434 [00:00<00:10, 1641.82it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Fold 1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2429.31it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2445.34it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2504.07it/s]\n",
      "  2%|▏         | 285/17434 [00:00<00:06, 2836.01it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 1 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 49.74%\n",
      "Model accuracy: 69.37%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 2\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2455.61it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2454.67it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2404.42it/s]\n",
      "  1%|▏         | 253/17434 [00:00<00:06, 2528.62it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 2 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 50.46%\n",
      "Model accuracy: 71.28%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2449.15it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2434.46it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2449.43it/s]\n",
      "  1%|▏         | 229/17434 [00:00<00:07, 2284.73it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 3 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 50.72%\n",
      "Model accuracy: 72.31%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 4\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2410.30it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2449.97it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2482.10it/s]\n",
      "  1%|▏         | 241/17434 [00:00<00:07, 2402.67it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 4 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 49.54%\n",
      "Model accuracy: 71.44%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2421.19it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2389.41it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2399.95it/s]\n",
      "  1%|▏         | 260/17434 [00:00<00:06, 2591.12it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 5 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 51.08%\n",
      "Model accuracy: 68.80%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 6\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2384.45it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2374.04it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2444.82it/s]\n",
      "  1%|▏         | 246/17434 [00:00<00:06, 2456.35it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 6 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 49.33%\n",
      "Model accuracy: 72.16%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 7\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2426.39it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2412.88it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2300.06it/s]\n",
      "  1%|▏         | 253/17434 [00:00<00:06, 2513.47it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 7 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 50.31%\n",
      "Model accuracy: 72.83%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 8\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2428.15it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2417.47it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2365.08it/s]\n",
      "  1%|▏         | 232/17434 [00:00<00:07, 2317.83it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 8 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 50.93%\n",
      "Model accuracy: 69.89%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 9\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2380.16it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2395.82it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2376.95it/s]\n",
      "  2%|▏         | 268/17434 [00:00<00:06, 2678.38it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 9 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 51.45%\n",
      "Model accuracy: 69.99%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "\n",
      "Fold 10\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17434/17434 [00:07<00:00, 2420.64it/s]\n",
      "100%|██████████| 17434/17434 [00:07<00:00, 2409.14it/s]\n",
      "100%|██████████| 1936/1936 [00:00<00:00, 2353.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting naive_bayes classifier...\n",
      "\n",
      "FOLD 10 RESULTS\n",
      "+ -------------------------------------------------- +\n",
      "Random baseline accuracy: 49.69%\n",
      "Model accuracy: 69.89%\n",
      "+ -------------------------------------------------- + \n",
      "\n",
      "Complete.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\"\"\" save experiment info to file \"\"\"\n",
    "\n",
    "results_df.to_pickle('./clf-results/results_df.pickle')\n",
    "fold_vector_df.to_pickle('./clf-results/fold_vector_df.pickle')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\"\"\" feature space \"\"\"\n",
    "\n",
    "print(\"Num Features (= |V|)\")\n",
    "print(\"+\", \"-\" * 50, \"+\")\n",
    "\n",
    "print(\"Minimum features across folds:\", min(results_df['vocabsize'].values))\n",
    "print(\"Maximum features across folds:\", max(results_df['vocabsize'].values))\n",
    "\n",
    "print(\"+\", \"-\" * 50, \"+\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num Features (= |V|)\n",
      "+ -------------------------------------------------- +\n",
      "Minimum features across folds: 8668\n",
      "Maximum features across folds: 8703\n",
      "+ -------------------------------------------------- +\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\"\"\" accuracy avg over folds \"\"\"\n",
    "\n",
    "correct = np.sum(fold_vector_df['random-baseline'].values == fold_vector_df['actuals'].values)\n",
    "accuracy = correct / len(fold_vector_df['random-baseline'].values)\n",
    "print(\"Random baseline accuracy across all folds: {:.2%}\".format(accuracy))\n",
    "\n",
    "\n",
    "correct = np.sum(fold_vector_df['predictions'].values == fold_vector_df['actuals'].values)\n",
    "accuracy = correct / len(fold_vector_df['predictions'].values)\n",
    "print(\"Model accuracy across all folds: {:.2%}\".format(accuracy))\n",
    "\n",
    "results_df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random baseline accuracy across all folds: 50.33%\n",
      "Model accuracy across all folds: 70.80%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   seed  fold  accuracy  random_baseline_accuracy  vocabsize  len(train)  \\\n",
       "0    20     0  0.693698                  0.497417       8672       17434   \n",
       "1    20     1  0.712810                  0.504649       8694       17434   \n",
       "2    20     2  0.723140                  0.507231       8692       17434   \n",
       "3    20     3  0.714360                  0.495351       8697       17434   \n",
       "4    20     4  0.688017                  0.510847       8696       17434   \n",
       "5    20     5  0.721591                  0.493285       8703       17434   \n",
       "6    20     6  0.728306                  0.503099       8686       17434   \n",
       "7    20     7  0.698864                  0.509298       8668       17434   \n",
       "8    20     8  0.699897                  0.514463       8672       17434   \n",
       "9    20     9  0.698864                  0.496901       8683       17434   \n",
       "\n",
       "   len(test)   % train    % test test label distribution  \n",
       "0       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "1       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "2       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "3       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "4       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "5       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "6       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "7       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "8       1936  0.900052  0.099948        {0: 968, 1: 968}  \n",
       "9       1936  0.900052  0.099948        {0: 968, 1: 968}  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>random_baseline_accuracy</th>\n",
       "      <th>vocabsize</th>\n",
       "      <th>len(train)</th>\n",
       "      <th>len(test)</th>\n",
       "      <th>% train</th>\n",
       "      <th>% test</th>\n",
       "      <th>test label distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693698</td>\n",
       "      <td>0.497417</td>\n",
       "      <td>8672</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712810</td>\n",
       "      <td>0.504649</td>\n",
       "      <td>8694</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.507231</td>\n",
       "      <td>8692</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714360</td>\n",
       "      <td>0.495351</td>\n",
       "      <td>8697</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.688017</td>\n",
       "      <td>0.510847</td>\n",
       "      <td>8696</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.721591</td>\n",
       "      <td>0.493285</td>\n",
       "      <td>8703</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.728306</td>\n",
       "      <td>0.503099</td>\n",
       "      <td>8686</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.509298</td>\n",
       "      <td>8668</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>0.514463</td>\n",
       "      <td>8672</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.496901</td>\n",
       "      <td>8683</td>\n",
       "      <td>17434</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>{0: 968, 1: 968}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\"\"\" precision and recall \"\"\"\n",
    "\n",
    "def clf_performance(fold_vector_df, metric='accuracy', label='o5'):\n",
    "    \"\"\"\n",
    "    metric: string specifying the performance metric (default='accuracy'\n",
    "            other options: 'precision', 'recall', 'f1_score')\n",
    "    class_type: default='mhp'\n",
    "                other options: 'peer'\n",
    "    \"\"\"\n",
    "\n",
    "    class_df = fold_vector_df[fold_vector_df['predictions'] == label]\n",
    "    other_df = fold_vector_df[fold_vector_df['predictions'] != label]\n",
    "\n",
    "    tp = np.sum(class_df['predictions'].values == class_df['actuals'].values)\n",
    "    tn = np.sum(other_df['predictions'].values == other_df['actuals'].values)\n",
    "    fp = np.sum(class_df['predictions'].values != class_df['actuals'].values)\n",
    "    fn = np.sum(other_df['predictions'].values != other_df['actuals'].values)\n",
    "        \n",
    "    if metric == 'accuracy':\n",
    "        return (tp + tn) / (tp + fn + fp + tn)\n",
    "    elif metric == 'precision':\n",
    "        return tp / (tp + fp)\n",
    "    elif metric == 'recall':\n",
    "        return tp / (tp + fn)\n",
    "    elif metric == 'f1_score':\n",
    "        prec = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        return 2 * prec * recall / (prec + recall)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "table = defaultdict(lambda:[])\n",
    "table['Model'].append(classifier)\n",
    "\n",
    "labels = ['mhp', 'peer']\n",
    "\n",
    "for label in labels:\n",
    "    precision = clf_performance(fold_vector_df, label=label, metric='precision')\n",
    "    recall = clf_performance(fold_vector_df, label=label, metric='recall')\n",
    "    f1 = clf_performance(fold_vector_df, label=label, metric='f1_score')\n",
    "\n",
    "    column = '{}: '.format(label)\n",
    "    table[column + 'P'].append(\"{:.3f}\".format(precision))\n",
    "    table[column + 'R'].append(\"{:.3f}\".format(recall))\n",
    "    table[column + 'F1'].append(\"{:.3f}\".format(f1))\n",
    "\n",
    "table = pd.DataFrame(table, columns=table.keys())\n",
    "\n",
    "print(\"Table: Precision and Recall results.\")\n",
    "print(\"+\", \"-\" * 100, \"+\")\n",
    "print(table.to_markdown(index=None))\n",
    "print(\"+\", \"-\" * 100, \"+\")\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table: Precision and Recall results.\n",
      "+ ---------------------------------------------------------------------------------------------------- +\n",
      "| Model       |   mhp: P |   mhp: R |   mhp: F1 |   peer: P |   peer: R |   peer: F1 |\n",
      "|:------------|---------:|---------:|----------:|----------:|----------:|-----------:|\n",
      "| naive_bayes |    0.718 |    0.685 |     0.701 |     0.699 |     0.731 |      0.715 |\n",
      "+ ---------------------------------------------------------------------------------------------------- +\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\"\"\" statistical significance test using non-parametric bootstrap resampling \"\"\"\n",
    "\n",
    "def prediction_differences(model_predictions, baseline_predictions, actuals):\n",
    "    differences = []\n",
    "    for model_pred, baseline_pred, actual in zip(model_predictions, baseline_predictions, actuals):\n",
    "\n",
    "        # both correct\n",
    "        if model_pred == actual and baseline_pred == actual:\n",
    "            difference = 0\n",
    "        # both incorrect\n",
    "        elif model_pred != actual and baseline_pred != actual:\n",
    "            difference = 0\n",
    "        # model correct but baseline is not\n",
    "        elif model_pred == actual and baseline_pred != actual:\n",
    "            difference = 1\n",
    "        # baseline correct but model is not\n",
    "        elif model_pred != actual and baseline_pred == actual:\n",
    "            difference = -1\n",
    "\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "def bootstrap_resampling_test(differences, N=10000):\n",
    "    # 1 = helped, 0 = not helped\n",
    "    resample_results = []\n",
    "    K = len(differences)\n",
    "    print(\"Beginning bootstrap resampling\")\n",
    "    for i in tqdm(range(N)):\n",
    "        samples = random.choices(differences, k=K)\n",
    "        summed_differences = sum(samples)\n",
    "        helped = summed_differences > 0\n",
    "        resample_results.append(helped)\n",
    "\n",
    "    helped_counts = Counter(resample_results)\n",
    "\n",
    "    p_value = (N - helped_counts[True]) / N\n",
    "    return p_value, helped_counts\n",
    "\n",
    "\n",
    "# get difference between predictions and random baseline\n",
    "prediction_differences = prediction_differences(fold_vector_df['predictions'].values, fold_vector_df['random-baseline'].values, fold_vector_df['actuals'].values)\n",
    "\n",
    "# run test\n",
    "N = 10000\n",
    "p_value, helped_counts = bootstrap_resampling_test(prediction_differences, N=N)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nStatistical significance test results\")\n",
    "print(\"+\", \"-\" * 50, \"+\")\n",
    "\n",
    "print(\"Model helps in {}/{} or {:.2%} of bootstrap resamples\".format(helped_counts[True], sum(helped_counts.values()), helped_counts[True]/sum(helped_counts.values())))\n",
    "\n",
    "print(\"p-value < {}\".format((N - helped_counts[True] + 1) / N ))\n",
    "\n",
    "correct = np.sum(fold_vector_df['predictions'].values == fold_vector_df['actuals'].values)\n",
    "accuracy = correct / len(fold_vector_df['predictions'].values)\n",
    "print(\"Accuracy across all folds: {:.2%}\".format(accuracy))\n",
    "print(\"+\", \"-\" * 50, \"+\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 49/10000 [00:00<00:20, 485.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Beginning bootstrap resampling\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 511.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Statistical significance test results\n",
      "+ -------------------------------------------------- +\n",
      "Model helps in 10000/10000 or 100.00% of bootstrap resamples\n",
      "p-value < 0.0001\n",
      "Accuracy across all folds: 70.80%\n",
      "+ -------------------------------------------------- +\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ee63c790a77d7036f2f29d0bbfb2d7b56db2f4f75f78f475c003fbfe0f8ccb3e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}